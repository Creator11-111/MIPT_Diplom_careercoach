"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π

–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ - —ç—Ç–æ –≤–µ–∫—Ç–æ—Ä—ã —á–∏—Å–µ–ª, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–º—ã—Å–ª —Ç–µ–∫—Å—Ç–∞.
–ü–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ Parquet —Ñ–∞–π–ª–∞
2. –î–ª—è –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ YandexGPT
3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ —Ñ–∞–π–ª—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
4. –°—Ç—Ä–æ–∏—Ç FAISS –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞

–í–ê–ñ–ù–û: –¢—Ä–µ–±—É–µ—Ç—Å—è API –∫–ª—é—á YandexGPT!
"""

from __future__ import annotations

import os
import sys
import numpy as np
from pathlib import Path
from typing import List, Dict, Any
import polars as pl
from tqdm import tqdm
import time

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ app –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.yandex_sdk import embed_text
from app.config import get_settings


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
VACANCIES_PARQUET = "financial_coach/data/financial_vacancies.parquet"
EMBEDDINGS_DIR = "financial_coach/data/embeddings/vacancies"
BATCH_SIZE = 100  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏


def create_text_for_embedding(vacancy: Dict[str, Any]) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –Ω–∞–≤—ã–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è.
    
    Args:
        vacancy: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏–∏
        
    Returns:
        –¢–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    """
    parts = []
    
    # –ù–∞–∑–≤–∞–Ω–∏–µ
    if title := vacancy.get("title"):
        parts.append(f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {title}")
    
    # –û–ø–∏—Å–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤)
    if description := vacancy.get("description"):
        description = description[:1000] if len(description) > 1000 else description
        parts.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")
    
    # –ù–∞–≤—ã–∫–∏
    if skills := vacancy.get("key_skills"):
        parts.append(f"–ù–∞–≤—ã–∫–∏: {skills}")
    
    # –ö–æ–º–ø–∞–Ω–∏—è –∏ –ª–æ–∫–∞—Ü–∏—è
    if company := vacancy.get("company"):
        parts.append(f"–ö–æ–º–ø–∞–Ω–∏—è: {company}")
    if location := vacancy.get("location"):
        parts.append(f"–õ–æ–∫–∞—Ü–∏—è: {location}")
    
    return "\n".join(parts)


def generate_embeddings_for_vacancies(
    vacancies: List[Dict[str, Any]],
    output_dir: str,
    batch_size: int = BATCH_SIZE
) -> None:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
    
    Args:
        vacancies: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π...")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {output_dir}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
    existing_files = list(Path(output_dir).glob("embeddings_batch_*.npy"))
    if existing_files:
        existing_nums = [int(f.stem.split("_")[-1]) for f in existing_files]
        last_batch = max(existing_nums)
        start_idx = last_batch * batch_size
        print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(existing_files)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–∞—Ç—á–µ–π. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏–Ω–¥–µ–∫—Å–∞ {start_idx}")
    else:
        start_idx = 0
        last_batch = 0
    
    embeddings_list = []
    indices_list = []
    processed_count = 0
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –±–∞—Ç—á–∞–º–∏
    for i in tqdm(range(start_idx, len(vacancies), batch_size), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–µ–π"):
        batch = vacancies[i:i + batch_size]
        batch_num = (i // batch_size) + 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —ç—Ç–æ—Ç –±–∞—Ç—á
        embeddings_path = os.path.join(output_dir, f"embeddings_batch_{batch_num}.npy")
        if os.path.exists(embeddings_path):
            print(f"‚è≠Ô∏è  –ë–∞—Ç—á {batch_num} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
            continue
        
        for vacancy in batch:
            try:
                # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                text = create_text_for_embedding(vacancy)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding = embed_text(text, model_kind="doc")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                embeddings_list.append(embedding)
                indices_list.append(vacancy.get("idx", 0))
                processed_count += 1
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.1)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy.get('idx')}: {e}")
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞—Ç—á–µ
        if embeddings_list:
            try:
                embeddings_array = np.array(embeddings_list, dtype="float32")
                indices_array = np.array(indices_list, dtype="int32")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                indices_path = os.path.join(output_dir, f"indices_batch_{batch_num}.npy")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ç–æ–º–∞—Ä–Ω–æ (—Å–Ω–∞—á–∞–ª–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –ø–æ—Ç–æ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º)
                temp_emb_path = embeddings_path + ".tmp"
                temp_idx_path = indices_path + ".tmp"
                
                np.save(temp_emb_path, embeddings_array)
                np.save(temp_idx_path, indices_array)
                
                # –ê—Ç–æ–º–∞—Ä–Ω–æ–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
                os.rename(temp_emb_path, embeddings_path)
                os.rename(temp_idx_path, indices_path)
                
                print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –±–∞—Ç—á {batch_num}: {len(embeddings_list)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                
                # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞—Ç—á–∞
                embeddings_list = []
                indices_list = []
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –±–∞—Ç—á–∞ {batch_num}: {e}")
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ
                for temp_file in [embeddings_path + ".tmp", indices_path + ".tmp"]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                raise
    
    print(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –≤–∞–∫–∞–Ω—Å–∏–π")
    print(f"üíæ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*60)
    print("üîç –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –î–õ–Ø –§–ò–ù–ê–ù–°–û–í–´–• –í–ê–ö–ê–ù–°–ò–ô")
    print("="*60)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
    if not os.path.exists(VACANCIES_PARQUET):
        print(f"‚ùå –§–∞–π–ª {VACANCIES_PARQUET} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print(f"üìù –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞:")
        print(f"   python data_parsing/scrape_financial_vacancies_hh.py")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ YandexGPT
    settings = get_settings()
    if not settings.yandex_folder_id or not (settings.yandex_api_key or settings.yandex_iam_token):
        print("‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω YandexGPT!")
        print("üìù –£–∫–∞–∂–∏—Ç–µ YANDEX_FOLDER_ID –∏ YANDEX_API_KEY –≤ —Ñ–∞–π–ª–µ .env")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ {VACANCIES_PARQUET}...")
    df = pl.read_parquet(VACANCIES_PARQUET)
    vacancies = df.to_dicts()
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π")
    print()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    generate_embeddings_for_vacancies(
        vacancies=vacancies,
        output_dir=EMBEDDINGS_DIR,
        batch_size=BATCH_SIZE
    )
    
    print()
    print("="*60)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("="*60)
    print()
    print("üìù –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ API –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print("   python -m uvicorn app.main:app --reload")


if __name__ == "__main__":
    main()














