"""
–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ Parquet —Ñ–∞–π–ª–∞ –≤ MongoDB.
"""

from __future__ import annotations

import os
from typing import Any

import polars as pl

from app.db.mongo import get_db


PARQUET_PATH = os.environ.get(
    "VACANCIES_PARQUET_PATH",
    os.path.join(os.path.dirname(__file__), "..", "..", "data", "financial_vacancies.parquet"),
)


async def seed_vacancies_if_needed() -> None:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ Parquet —Ñ–∞–π–ª–∞ –≤ MongoDB."""
    if not os.path.exists(PARQUET_PATH):
        print(f"‚ö†Ô∏è  –§–∞–π–ª —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {PARQUET_PATH}")
        print("üìù –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é CSV –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ HH.ru")
        return

    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑: {PARQUET_PATH}")

    df = pl.read_parquet(PARQUET_PATH)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ —Ñ–∞–π–ª–∞")

    required_cols: dict[str, Any] = {
        "idx": pl.UInt32,
        "‚Ññ": pl.Int64,
        "id": pl.Int64,
        "title": pl.Utf8,
        "salary": pl.Utf8,
        "experience": pl.Utf8,
        "job_type": pl.Utf8,
        "description": pl.Utf8,
        "key_skills": pl.Utf8,
        "company": pl.Utf8,
        "location": pl.Utf8,
        "date_of_post": pl.Utf8,
        "type": pl.Utf8,
    }

    for col, dtype in required_cols.items():
        if col not in df.columns:
            df = df.with_columns(pl.lit(None).cast(dtype).alias(col))
        else:
            df = df.with_columns(pl.col(col).cast(dtype, strict=False))

    df = df.select(list(required_cols.keys()))

    db = await get_db()
    coll = db["vacancies"]

    print("üîç –ü—Ä–æ–≤–µ—Ä—è—é —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –±–∞–∑–µ...")
    existing = set()
    async for doc in coll.find({}, {"idx": 1}):
        if "idx" in doc:
            existing.add(int(doc["idx"]))

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(existing)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π")

    to_insert = [
        {k: (None if v == "" else v) for k, v in row.items()}
        for row in df.to_dicts()
        if int(row.get("idx", -1)) not in existing
    ]

    if to_insert:
        print(f"üíæ –î–æ–±–∞–≤–ª—è—é {len(to_insert)} –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞–∑—É...")
        await coll.create_index("idx")
        await coll.insert_many(to_insert)
        print("‚úÖ –í–∞–∫–∞–Ω—Å–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
    else:
        print("‚ÑπÔ∏è  –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

    total_count = await coll.count_documents({})
    print(f"üìä –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞–∑–µ: {total_count}")










